\documentclass[format=sigplan, review=false, screen=true]{acmart}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{fontspec}
\setmonofont[
  Contextuals={Alternate},
  Scale=0.9
]{Fira Code}
\makeatletter
\def\verbatim@nolig@list{}
\makeatother

\usepackage{booktabs} % For formal tables
\usepackage{bussproofs}
\usepackage{graphics}
\usepackage{xcolor}

\usepackage{minted}
\usemintedstyle{friendly}
\setminted{
    frame=lines,
    framesep=2mm,
    baselinestretch=1.2,
    %bgcolor=lightgray,
    fontsize=\footnotesize,
    escapeinside=\#\#
    }

\usepackage{filecontents}

\usepackage[ruled]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

\usepackage{listings}
\lstdefinestyle{mystyle}{
    %backgroundcolor=\color{backcolour},   
    commentstyle=\color{gray},
    keywordstyle=\color{blue},
    numberstyle=\tiny,
    stringstyle=\color{purple},
    basicstyle=\small\tt,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    %numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,
    frame=single,
    xleftmargin=1em,
    xrightmargin=1em,
    frame=shadowbox,
    rulesepcolor=\color{gray},
    tabsize=2
}
 
\lstset{style=mystyle,
  literate=
  {->} {$\to$} 2
  {<-} {$\leftarrow$} 2
  {=>} {$\Rightarrow$} 2
  {forall} {$\forall$} 1
  {exists} {$\exists$} 1
  {phi} {$\varphi$} 1
  {rho} {$\rho$} 1
  {kappa} {$\kappa$} 1
  {$nu$} {$\nu$} 1
  {$mu$} {$\mu$} 1
  {gamma} {$\gamma$} 1
  {subsetX} {$\subset$} 1
  {~>} {$\rightsquigarrow$} 2
  {<~>} {$\leftrightsquigarrow$} 3
  {elem} {$\in$} 1
}

\usepackage{cleveref}

% Metadata Information
\acmJournal{TWEB}
\acmVolume{9}
\acmNumber{4}
\acmArticle{39}
\acmYear{2018}
\acmMonth{3}
\copyrightyear{2018}
%\acmArticleSeq{9}

% Copyright
%\setcopyright{acmcopyright}
\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
\acmDOI{0000001.0000001}

% Paper history
\received{June 2018}
%\received[revised]{March 2009}
%\received[accepted]{June 2009}

% Document starts
\begin{document}
% Title portion. Note the short title for running heads
\title[Ghosts of Departed Proofs]{Functional Pearl: Ghosts of Departed Proofs}

\author{Matt Noonan}
\orcid{1234-5678-9012-3456}
\affiliation{%
  \institution{Kataskeue LLC}
%  \streetaddress{Esty St}
  \city{Ithaca}
  \state{NY}
  \postcode{14850}
  \country{USA}}
\email{mnoonan@kataskeue.com}


\begin{abstract}

  We present a simple technique that allows library authors to
  control how APIs are used.

\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}

%
% End generated code
%


\keywords{Wireless sensor networks, media access control,
multi-channel, radio interference, time synchronization}




\maketitle

% The default list of authors is too long for headers.
\renewcommand{\shortauthors}{M. Noonan}

%\input{samplebody-journals}

\section{Introduction}

One practical benefit of a powerful type
system is the ability to enforce sophisticated program
invariants at compile time. *** mention dependent types,
refinement types.

In the context of API design, Microsoft program manager
Rico Mariani coined the dual terms ``pit of despair'' and
``pit of success''. A pit is easy to fall into; APIs that
make it easy to do the wrong thing lead the user into a ``pit of despair''.
Conversely, APIs that make it easy to do the \emph{right} thing
have a ``pit of success''. For example, an API ***

\begin{quote}
  [Rico] admonished us to think about how we can build platforms that lead developers to write great, high performance code such that developers just fall into doing the "right thing". That concept really resonated with me. It is the key point of good API design. We should build APIs that steer and point developers in the right direction.
\end{quote}

What is the root cause of this frustration that drives
well-intentioned programmers towards 


For example, a recent snapshot of \texttt{hackage}
reveals over 2000 instances where the partial function
\texttt{fromJust} is applied to the
result of \texttt{Data.Map}'s \texttt{lookup}. Each one
records the moment a programmer fell into a pit of despair:
they have somehow reasoned that a certain key must be
present in the map, but were given no mechanism for
\emph{communicating} that reasoning to the
\texttt{Data.Map} API. To escape the pit, they made the
pragmatic---but unsafe---decision to introduce partiality.

\begin{filecontents*}{idioms.hs}
--------------------------------------------------------
-- Unsafe API using non-total functions.

head :: [a] -> a
head xs = case xs of
  (x:_) -> x
  []    -> error "empty list!"

endpts = do
  putStrLn "Enter a non-empty list of integers:"  
  xs <- readLn
  if xs /= [] then return (head xs, head $ reverse xs)
              else endpts

--------------------------------------------------------
-- Returning Maybe / Optional values. Safe, but requires
-- the caller to pattern-match on the Maybe at every use,
-- even when the list is known to be non-empty.

safeHead :: [a] -> Maybe a
safeHead xs = case xs of
  (x:_) -> Just x
  []    -> Nothing

safeEndpts = do
  putStrLn "Enter a non-empty list of integers:"  
  xs <- readLn
  case (safeHead xs, safeHead $ reverse xs) of
    (Just x, Just y) -> return (x, y)
     _               -> safeEndpts

-------------------------------------------------------
-- "Ghosts of Departed Proofs". Safe. Does not return
-- an optional value; preconditions are checked early
-- and represented in phantom type parameters.

gdpHead :: List NonZero a -> a
gdpHead xs = case the xs of
  (x:_) -> x
  []    -> unreachable

gdpEndpts = do
  putStrLn "Enter a non-empty list of integers:"  
  xs <- readLn
  case classify xs of
    Right xs -> return (gdpHead xs, gdpHead $ gdpRev xs)
    Left  _  -> gdpEndpts
\end{filecontents*}

\begin{figure}
  \inputminted{haskell}{idioms.hs}
  \caption{Idioms for implementing the
    \texttt{head} function, along with usage examples.
    The \texttt{gdpHead} function can only be invoked in
    a context where the user has already proven that the
    list is non-empty, combining the simplicity of the
    first example with the safety of the second.}
\end{figure}

\subsection{Common idioms for handling pre-conditions}

No matter the language, a programmer often has to write functions
that place constraints on their input. For example, the venerable
\texttt{head} function for extracting the first element of a list
asks its users to only hand it a non-empty list to operate on.


\paragraph{Run-time failure on bad inputs.}
Often the simplest approach is
  to have a function simply fail on malformed inputs. The failure can
  be a run-time error (as in Haskell's \texttt{head}), or result in
  undefined behavior (as in \texttt{C++}'s \texttt{std::vector<T>::front()}).
  
\paragraph{Returning a dummy value.}
  To avoid run-time errors, some APIs may have a ``dummy value''
  for indicating the result of a failed operation. For example, Common Lisp's
  \texttt{car} and \texttt{golang}'s \texttt{Front()} both return \texttt{nil}
  when passed an empty list. The caller must explicitly check for this dummy
  value. Other contortions may be needed if the container is also allowed to
  hold \texttt{nil}, to disambiguate between ``the input list was empty'' and
  ``\texttt{nil} is the first element of this list''.

\paragraph{Returning a value with an option type.}
  A similar ``dummy value'' strategy
  for languages with stricter typing discipline is to use an ``option type'' such
  as Haskell's \texttt{Maybe} or Scala's \texttt{Option}. A value of type \texttt{Maybe a}
  cannot be used where a value of type \texttt{a} was expected, so the user must
  explicitly pattern match on the optional value to extract the result and handle the
  error case. This approach may lead to frustration when the user believes that the
  error case is not possible.
  
\paragraph{Modifying input types to exclude bad inputs.}
Finally, the API designer may select more restrictive types for the inputs in order
to make the function total. For example, some Haskell libraries make use of the
\texttt{NonEmpty} type for lists that contain at least one element. The \texttt{head}
function then becomes total. Rather than handling a failure case, the user only
needs to prove that their list is non-empty by making use of the smart constructor
\texttt{nonEmpty :: [a] -> Maybe (NonEmpty a)}.

\subsection{Ghosts of Departed Proofs}
The ``return-an-optional-value'' idiom is well-known in the functional programming world.
The author of a library function that returns \texttt{Maybe a} can certainly sleep well
at night, content in the knowledge that their function will never cause a run-time error.

But what about the \emph{users} of that library? Has the library author helped the user stay
on a virtuous path, or have they led the user into temptation?

In fact, the author of the library has just pushed extra responsiblity onto the user.
Every time the user applies a function that uses the optional-return idiom, they are obligated
to test the return value and handle the error case. This remains true, even if the user
has \emph{correctly} ensured that the function's preconditions have been met! The library
author sleeps well while even the most cautious users toil against those impossible error cases.

No wonder, then, that so many well-meaning users reach for unsafe functions like \texttt{fromJust}!
They have already proved (to their own satisfaction) that the function is being used properly, so they rightly
feel justified in ignoring the error case entirely. But now we see how the user has been led into
a pit of despair: they have ended up with a program that is \emph{exactly as fragile} as one where the library
author had used the run-time-failure idiom!\footnote{In fact, things are slightly \emph{worse}: we have also introduced a little
bit of extra allocation and indirection for creating and unpacking the return value in the non-error case.}

In this paper, we will use a series of case studies to show how library authors can write
functions that can ensure certain pre-conditions are met, without the 

\section{Warm-up: Faux dependent types}

\begin{filecontents*}{ex1.hs}  
{-# LANGUAGE RankNTypes #-}
module Sized
  (Size, the, sZipWith, sizing, align) where

newtype List n a = List a

the :: List n a -> a
the (List x) = x

sZipWith :: (a -> b -> c)
         -> List n a
         -> List n b
         -> List n c
sZipWith f xs ys =
  List (zipWith f (the xs) (the ys))
  
sizing :: [a] -> (forall n. List n a -> t) -> t
sizing xs k = k (List xs)

align :: List n a -> [b] -> Maybe (List n b)
align xs ys = if length (the xs) == length ys
              then Just (List ys)
              else Nothing

\end{filecontents*}

\begin{filecontents*}{ex2.hs}
import Sized

dot :: List n Double -> List n Double -> Double
dot xs ys = sum (the $ sZipWith (*) xs ys)

main :: IO ()
main = do
  xs <- readLn
  ys <- readLn
  sizing xs $ \xs' -> do
    case align xs' ys of
      Nothing  -> putStrLn "List mismatch!"
      Just ys' -> print (dot xs' ys')
\end{filecontents*}

\begin{figure}
    \inputminted{haskell}{ex1.hs}
  \caption{A small module defining a type for lists with a known length.}
\end{figure}
\begin{figure}
    \inputminted{haskell}{ex2.hs}
    \caption{A user-defined dot product function that can only be used on same-sized lists,
    and a usage example. \label{dot-product}}
\end{figure}

Despite  appearences, the phantom type parameter $n$ does not really represent the vector's length
{\em per se}. Instead, we propose to think of the phantom type \texttt{p} in \texttt{List p a} as a predicate,
and values of type \texttt{List n a} as ``lists of type \texttt{[a]}, equipped with a proof
that they satisfy \texttt{p}''. Critically, this proof has no run-time impact: it is trapped in the
phantom type parameter, and carried by a \texttt{newtype} wrapper that vanishes in
the final compilation.


As we attach increasingly sophisticated information into the phantom types, it becomes useful to
have a uniform method for \emph{forgetting} all of the ornamentation, revealing the normal
value underneath.

In \cref{dot-product}, note that the error handler for mismatched list sizes happens
\emph{outside} of the dot product function. At the point where the \texttt{dot} function
is actually invoked, the programmer has already provided evidence that the operation is
safe, in the form of the phantom type parameters on \texttt{xs'} and \texttt{ys'}.

\subsection{A feint towards dependent types}
So far, the \texttt{Sized} API allows us to assert that two lists are known to have the same
length, and to introduce an existentially-quantified (but unknown) size for a ``regular'' list.
As the authors of the \texttt{Sized} module, we can introduce more interesting variations as
well. For example, we could types that represent a length of zero, or an even length, or the
sum of two other lenghts, or an infinite length; indeed, any class of lengths that we
think the user might want.

\begin{minted}{haskell}
data Zero
data NonZero
data Add x y

nil :: List Zero a
nil = List []

gdpHead :: List NonZero a -> a
gdpHead xs = head (the xs) -- safe!

gdpRev :: List n a -> List n a
gdpRev = coerce . reverse . coerce

classify :: [a] -> Either (List Zero a) (List NonZero a)
classify xs = case xs of
  []    -> Left  (coerce xs)
  (_:_) -> Right (coerce xs)
  
(+++) :: List n a -> List m a -> List (Add n m) a
xs +++ ys = coerce (the xs ++ the ys)

zero_neutral :: List (Add Zero n) a -> List n a
zero_neutral = coerce

add_commutes :: List (Add n m) a -> List (Add m n) a
add_commutes = coerce
\end{minted}

Except in the simplest of cases, it is important that the library author equip the
user with a selection of \emph{proof combinators} for changing the shape of the
property captured by the phantom type parameter. In ****, \texttt{zero\_neutral}
and \texttt{add\_commutes} are proof combinators that allow the user to convert
evidence from one form to another.

\begin{minted}{haskell}
head' :: List NonZero a -> a
head' xs = gdpHead (ok $ nil +++ xs)
  where
    ok = zero_neutral

norm2 :: List n Double -> Double
norm2 xs = dot xs (ok $ xs +++ nil)
  where
    ok = zero_neutral . add_commutes
\end{minted}

*** It is not so much effort to introduce a \texttt{NonEmpty} type for lists, but it
would be intractable to add \texttt{EvenSizedList}, \texttt{InfiniteList},
\texttt{EmptyList}, and so on. Each library function would need a variant
for each new type, or else a carefully curated collection of typeclasses would
be required to provide \emph{ad hoc} overloading. By contrast, the GDP approach
allows the same library functions on a wide variety of *******.

\subsection{Infinite lists}

\begin{minted}{haskell}
data Infinite

omega :: List Infinite Int
omega = List [0..]

pop :: List Infinite a -> (a, List Infinite a)
pop (List xs) = (head xs, List (tail xs))
\end{minted}

\begin{filecontents*}{theTC.hs}
class The d a | d -> a where
    the :: d -> a
    default the :: Coercible d a => d -> a
    the = coerce
    
instance The (List n a) a
\end{filecontents*}

\begin{figure}
  \inputminted{haskell}{theTC.hs}
  \caption{The \texttt{The} typeclass, for dropping ghosts
    from a type. The default instance should always be used,
    so new instances can be created with an empty
    \texttt{instance} declaration.}
\end{figure}

\section{And what inhabits these phantom types?}
They represent neither run-time values nor type-level computation, nor yet nothing.
May we not call them Ghosts of Departed Proofs?

The techniques described in this paper can be applied to many
situations that traditionally would belong to the domain of
\emph{dependent types} or \emph{refinement types}. However, the
GDP approach has a few advantages:
\begin{itemize}
\item Only mild extensions to a Damas-Hindley-Milner type system
  ({\it e.g.} rank-2 types, a module system, phantom types) are required to
  implement the technique.
\item Propositions are encoded in the phantom types, so the
  \emph{proofs} are written in the normal value-level language.
  No type-level computation is required.
\item Proofs are explicit, not implicit as in Liquid Haskell. There is
  no reliance on third-party solvers that may fail to complete a check,
  or may vary in their behavior from platform to platform.
\item Proofs are concrete entities within the host language, and can
  be analyzed or audited independently. Tooling for the host language
  can be used within the proof language.
\end{itemize}

In the following sections, we will investigate several case studies that
demonstrate how the GDP approach can help create libraries for common
software engineering tasks, while ensuring that the end-user can only
use the library API safely. The theme throughout is:
\begin{itemize}
\item Use phantom type parameters to carry proofs that program invariants are satisfied.
\item Export combinators for manipulating these proofs.
\item Restrict the user's ability to introduce these proofs.
\end{itemize}

\section{Case Study \#2: Sorted lists}

Surely every programmer has, at some time, had to work with collections of
lists that were required to be sorted in one way or another. Within some
context, the programmer may need to ensure that certain invariants hold, such
as ``all of these lists have been sorted by the same comparator''. For a concrete
example, consider these \texttt{sortBy} and \texttt{mergeBy} functions:
\begin{minted}{haskell}
sortBy  :: (a -> a -> Ordering) -> [a] -> [a]

-- Usage constraint: in `mergeBy comp xs ys`, the
-- input lists `xs` and `ys` should also be sorted
-- by the same comparator `comp`.
mergeBy :: (a -> a -> Ordering) -> [a] -> [a] -> [a]
mergeBy comp xs ys = go xs ys
  where
    go []  ys' = ys'
    go xs' []  = xs'
    go (x:xs') (y:ys') = case comp x y of
      GT -> y : go (x:xs') ys'
      _  -> x : go xs' (y:ys')
\end{minted}
This efficient $O(n+m)$ implementation of \texttt{mergeBy} is easy to write,
but puts the onus on the caller of \texttt{mergeBy} to ensure that the
input lists have been sorted by the same comparator.

It would be possible to implement a version of \texttt{mergeBy} that
carefully inspected the inputs \texttt{xs} and \texttt{ys} as it
proceeded, and only produced a result if the inputs met the sorting
requirement. But this would impose a runtime cost on every use of
\texttt{mergeBy}, increase the complexity of its implementation,
and change the result type to \texttt{Maybe [a]}. And then what?
Most users of \texttt{mergeBy} would argue to themselves ``This is
absurd! I already know the input lists were sorted properly. This
function will never result in \texttt{Nothing}.'' It would be hard
to blame the user when they reach for an  unsafe function like
\texttt{fromJust :: Maybe a -> a}.

Clearly, there is little benefit for anybody in the above scenario. The
library author is inconvenienced by the increased implementation complexity.
The user is inconvenienced by the decreased performance and the need to
pattern match on the result, even when they believe they already know the
outcome of that match. No wonder that the status quo is to just write
the simple function along with a warning in the documentation, admonishing
any user who tries to \texttt{mergeBy} what they didn't \texttt{sortBy}.

But if the user really \emph{does} have evidence that the input lists have
been sorted properly, can we devise a mechanism by which they can convince
\texttt{mergeBy}?

\subsection{Conjuring a name}
The first problem that meet is how to reflect the notion of two  comparators
being ``the same''. In a language that supports equality tests on functions,
you could imagine a solution where the \texttt{sortBy} function returns a sorted
list along with a reference to the comparator that was used; \texttt{mergeBy} could
then check that the comparators matched. But this has a run-time cost for carrying
around the comparator references, and it still would require \texttt{mergeBy} to
return \texttt{Nothing} if it was given bogus arguments.

Following the GDP approach, we can introduce a proposition ``is named \texttt{name}'',
represented by a \texttt{newtype} wrapper with phantom type parameter \texttt{name}.
In code, we will write this proposition as \verb|a ~~ n|, to be read as
``values of type \texttt{a} with name \texttt{n}''. A simple module for named values
can be found in \cref{name-module}; the only property that we encode is
``any value can be given a name'', represented by the exported \texttt{name} function.

With the \texttt{Named} module, we can write some spooky functions. For example,
here is a function that can only be invoked by giving it two values with the same
name:
\begin{minted}{haskell}
same :: (a ~~ name) -> (a ~~ name) -> IO ()
same _ _ = putStrLn "same! (but you already knew that)"
\end{minted}
Since the \texttt{Named} module does not provide any mechanism for transferring
a name from one value to another, the \texttt{same} function can only be invoked
by passing the same value to both parameters.

Still less useful, these two functions cannot be invoked at all:
\begin{minted}{haskell}
data Bob

bobOnly :: (a ~~ Bob) -> IO ()
bobOnly _ = error "Hi, Bob!"

sameButDifferent :: (a ~~ name) -> (b ~~ name) -> IO ()
sameButDifferent _ _ = error "Impossible!"
\end{minted}
\begin{filecontents*}{named.hs}
module Named (Named, type (~~), name) where

import The

newtype Named name a = Named a
instance The (Named name a) a
type a ~~ name = Named name a

name :: a -> (forall name. (a ~~ name) -> t) -> t
name x k = k (coerce x)
\end{filecontents*}

\begin{filecontents*}{ordered.hs}
module Sorted
  (Named, SortedBy, sortBy, mergeBy) where   

import The
import Named

import qualified Data.List as L
import qualified Data.List.Utils as U

newtype SortedBy o a = SortedBy a
instance The (SortedBy o a) a
  
sortBy :: ((a -> a -> Ordering) ~~ comp)
       -> [a]
       -> SortedBy comp [a]
sortBy comp xs = coerce (L.sortBy (the comp) xs)

mergeBy :: ((a -> a -> Ordering) ~~ comp)
        -> SortedBy comp [a]
        -> SortedBy comp [a]
        -> SortedBy comp [a]
mergeBy comp xs ys =
  coerce (U.mergeBy (the comp) (the xs) (the ys))        
\end{filecontents*}

\begin{filecontents*}{usageO.hs}
import Sorted
import Named
main = do
  xs <- readLn :: IO Int
  ys <- readLn
  name (comparing Down) $ \gt -> do
    let xs' = sortBy gt xs
        ys' = sortBy gt ys
    print (the xs', the ys', the (mergeBy gt xs' ys'))
\end{filecontents*}

\begin{figure}
  \inputminted{haskell}{ordered.hs}
  \caption{A module for working with lists that have been sorted by an arbitrary
    comparator.}
\end{figure}


\begin{figure}
  \inputminted{haskell}{named.hs}
  \caption{A module for attaching ghostly names to values.\label{name-module}}
\end{figure}

\begin{figure}
  \inputminted{haskell}{usageO.hs}
  \caption{Usage example}
  \end{figure}
Clients of the library are somewhat more restricted, in the sense that they cannot create a
value of type \texttt{SortedBy comp t} without going through the library's public API.

\begin{minted}{haskell}
minimum_O1 :: SortedBy comp [a] -> Maybe a
minimum_O1 xs = case (the xs) of
    []    -> Nothing
    (x:_) -> Just x
\end{minted}

\subsection{The danger of naming a ghost}

Finally, for the user to be able to \emph{use} this library, there must be a way for
them to create \texttt{Named} values from normal values. The library must export a
function similar to this:

\begin{minted}{haskell}
name :: a -> (forall name. (a ~~ name) -> t) -> t
name x k = k (coerce x)
\end{minted}

This function is quite similar to \texttt{sizing} from the previous section, and the rank-2
type gives it a bit of an ominous feel. You might wonder: why not just have a function
with a simple type like this?

\begin{minted}{haskell}
any_name :: a -> (a ~~ name)
any_name = coerce
\end{minted}

The crux of the issue is all about \emph{who gets to choose} what \texttt{name} will be.
In the signature of \texttt{any\_name}, the \emph{caller} gets to select the types \texttt{a}
and \texttt{name}. In particular, they can attach any name they would like!

If that still does not sound so bad, consider this code:

\begin{minted}{haskell}
data Simon
  
up, down :: (Int -> Int -> Ordering) ~~ Simon
up   = any_name compare
down = any_name (comparing Down)

list1 = sortBy up   [1,2,3]
list2 = sortBy down [1,2,3]

merged = the (mergeBy up list1 list2) :: [Int]
-- [1,2,3,3,2,1]
\end{minted}
\noindent
The user has decided to name two different functions \texttt{Simon}, subverting the
guarantees offered by the API of the \texttt{Sorted} module. It is dangerous to
name a ghost!

Now compare to the analogous program, using \texttt{name} instead of \texttt{any\_name}:
\begin{minted}{haskell}
name compare $ \up ->
  name (comparing Down) $ \down ->
    let list1 = sortBy up   [1,2,3]
        list2 = sortBy down [1,2,3]
    in the (mergeBy up list1 list2)
\end{minted}
\noindent
This results in a compile-time error:

\begin{lstlisting}
  • Couldn't match type "name1" with "name"
        ...
    Expected type: SortedBy name [Integer]
      Actual type: SortedBy name1 [Integer]
\end{lstlisting}
\noindent
The critical difference is that a user of the library is not allowed to create a named
value by fiat. Instead, they are only allowed to \emph{consume} a named value, by
providing a polymorphic function that can work with \emph{any} named value. The library's API provides
a helper function---in this case, \texttt{name}---for applying the consumer to a normal, unnamed value.
In practice, it is as if the
library has a secret supply of names, and selects one to use in a manner that is not
predictable (or even inspectable!) to the user.

A general rule of thumb for library authors is:
\emph{a ghost should not appear in the return type,  unless it also appears in an argument's type}. This simple rule ensures that
the user of the library will not be allowed to materialize ghosts out of thin air.

\subsection{Names and the \texttt{ST} monad}
The trick for conjuring names outside of the user's control by using rank-2 types was
inspired by the \texttt{ST} monad and the rank-2 \texttt{runST :: (forall s. ST s a) -> a}
function \cite{launchbury1994lazy}. In fact, some authors have even proposed to think of the \texttt{s} parameter as
representing a name attached to a region of the heap \citep{timany2017logical}.

Informally, we can think of \texttt{ST s a} as representing a \texttt{State} monad over
named stores, such as
\begin{minted}{haskell}
data Store = Store

type St s = State (Store ~~ s)

runSt :: (forall s. St s a) -> a
runSt action = name Store (evalState action)
\end{minted}

\section{Case Study \#2: \texttt{Maybe}-free lookup in containers}

In this section, we will investigate the pit of despair that leads so
many developers to follow a map lookup by \texttt{fromJust}.

The power of this method becomes more apparent when considering maps where
the values are expected to reference the keys in some way. For example, a
simple representation for directed graphs with vertex type \texttt{v} is
\begin{minted}{haskell}
type Digraph v = Map v [v]
\end{minted}
mapping each vertex to its list of immediate neighbors. Well-formed \texttt{Digraph}s
should satisfy the property that every vertex referenced in any neighbor list is also
a valid key in the adjacency map.

\begin{filecontents*}{justified.hs}
newtype JMap ks k v = JMap (Map k v)
    deriving Functor

newtype k #$\in$# ks = Element k

instance The (JMap ks k v) (Map k v)
instance The (k #$\in$# ks)  k

member ::  k -> JMap ks k v -> Maybe (k #$\in$# ks)

lookup   :: k #$\in$# ks -> JMap ks k v -> v

reinsert
  :: k #$\in$# ks -> v -> JMap ks k v -> JMap ks k v

withMap
:: Map k v  -> (forall s. JMap s k v -> t) -> t
\end{filecontents*}

\begin{filecontents*}{justified-usage.hs}
test_table = Map.fromList [ (1, "Hello")
                          , (2, "world!") ]

withMap test_table $ \table ->
  case member 1 table of
 
    Nothing  -> putStrLn "Missing key!"
  
    Just key -> do
      putStrLn ("Found key: " ++ show (the key))
      putStrLn ("Value in map 1: " ++
                lookup key table)
      
      let table'  = reinsert key "Howdy" table
          table'' = fmap (map upper) table
      putStrLn ("Value in map 2: " ++
                lookup key table')
      putStrLn ("Value in map 3: " ++
                lookup key table'')
{- Output:
Found key: 1
Value in map 1: Hello
Value in map 2: Howdy
Value in map 3: HELLO
-}       
\end{filecontents*}

\begin{figure*}
  \begin{minipage}{0.48\textwidth}
    \inputminted{haskell}{justified.hs}
  \end{minipage}
  \begin{minipage}{0.48\textwidth}
    \inputminted{haskell}{justified-usage.hs}
  \end{minipage}
\end{figure*}

\subsection{Application: a type for directed graphs}

\begin{minted}{haskell}
data Neighbors keys = Neighbors
    { outEdges :: Vertex #$\in$# keys
    , inEdges  :: Vertex #$\in$# keys }
  
type Digraph keys = JMap keys Vertex (Neighbors keys)
\end{minted}

%% \begin{minted}{haskell}
%% addEdge   :: Vertex #$\in$# keys -> Vertex #$\in$# keys -> (forall keys'. Digraph keys' -> t) -> t
%% \end{minted}


%% \begin{minted}{haskell}
%% check :: Int -> Digraph φ -> Either (FreshVertex φ) (Vertex φ)
%% fresh :: Digraph φ -> FreshVertex φ
%% addVertex :: FreshVertex φ -> Digraph φ ->
%%             (forall φ'. (Vertex φ', Vertex φ -> Vertex φ', Digraph φ') -> t) -> t
%% \end{minted}


\subsection{Application: Faster lookup}
Although \texttt{justified-containers} defines a simple \texttt{newtype} wrapper for
the key-plus-phantom-proof type, more interesting information about the location of
the key within the corresponding data structure can sometimes be attached.

For example, imagine a simple binary search tree backed by a vector of key-value pairs.
As in the previous example, we will give the \texttt{BST} type a phantom parameter that
represents the set of valid keys present in the tree. But instead of wrapping the key
type directly, we will use an index-plus-phantom-proof representation for keys.

\begin{lstlisting}[language=Haskell]
newtype BST φ k v = BST (Vector (k,v))
newtype Index φ   = Index Int

toBST :: Ord k => Vector (k,v) -> BST phi k v

find   :: Ord k => k -> BST φ k v -> Maybe (Index phi)
access :: Index phi -> BST φ k v -> (k,v)
\end{lstlisting}

\subsection{Changing the key set}
*****
But what about maps that are related, yet do not have exactly the same key sets?
For example, the \texttt{insert} function will usually modify the key set of a map,
yet we know that if a key was present in the original map, it must still be present
in the expanded map. As a user, it would be quite frustrating if we had a key that
was valid in the original map, but we were unable to use it freely in the expanded map!

To support this use-case, \texttt{justified-containers} provides the functions
\texttt{inserting} and \texttt{deleting}, with these signatures:
\begin{minted}{haskell}
deleting  :: Ord k => k #$\in$# ks -> JMap ks k v
          -> (forall ks'. JMap ks' k v
                      -> (k #$\in$# ks' -> k #$\in$# ks)
                      -> t)
          -> t

inserting :: Ord k => k -> v -> JMap ks k v
          -> (forall ks'. JMap ks' k v
                       -> (k #$\in$# ks -> k #$\in$# ks')
                       -> k #$\in$# ks
                       -> t)
          -> t
\end{minted}
Since these functions each result in maps with new key sets, we must
introduce the ghost of these key sets inside another \texttt{forall}.
But what are the other parameters for? In the case of \texttt{inserting},
the computation has access to:
\begin{enumerate}
\item The updated map, of type \texttt{JMap ks' k v}. The phantom type \texttt{ks'}
  represents the key set \texttt{ks}, updated with the newly-inserted key.
\item A function that represents the inclusion of \texttt{ks} into \texttt{ks'}.
  The user can apply this function to convert a proof that a certain key belonged to the
  old map (that is, a value of type \texttt{k $\in$ ks}) into a proof that the key also belongs to the new map (a value of type \texttt{k $\in$ ks'}).
\item Evidence that the new key is present in the new key set.
\end{enumerate}

Similarly, the continuation for \texttt{deleting} has access to both the updated map
and a representation of the inclusion of keys from the new map into the old map.

The library author must do a bit of a balancing act here. It is important to provide
the user with a supply of evidence and proof combinators so that they are able to
express the fact that the API is being used properly, but it is not always clear how
much information should be added. For example, the user may well want to argue that a
every key \emph{other} than the deleted one is still present in a map modified by
\texttt{deleting}, but the API provides no straightforward way to do this.

\begin{filecontents*}{delete1.hs}
newtype Insert k v m = Insert Defn
newtype Delete k m   = Delete Defn

insert :: Ord k
       => (k ~~ k)
       -> (v ~~ v)
       -> (Map k v ~~ m)
       -> (Map k v ~~ Insert k v m)
insert k v m =
    defn (Map.insert (bare k) (bare v) (bare m))
       
delete :: Ord k
       => (k ~~ k ::: k #$\in$# KeySet m)
       -> (Map k v ~~ m)
       -> (Map k v ~~ Delete k m)
delete k m = defn (Map.delete (bare k) (bare m))
\end{filecontents*}
\begin{filecontents*}{delete2.hs}
subset_elts :: (a #$\subseteq$# b) -> (x #$\in$# a)
            -> Proof (x #$\in$# b)
subset_elts _ = sorry

insert_supset :: Proof (Keys m #$\subseteq$# Keys (Insert k v m))
insert_supset = sorry

key_is_present :: Proof (k #$\in$# Insert k v m)
key_is_present = sorry

delete_subset :: Proof (Keys (Delete k m) #$\subseteq$# Keys m)
delete_subset = sorry

key_is_missing  :: (k' #$\in$# Keys m) -> (k /= k')
                -> Proof (k' #$\in$# Keys (Delete k m))
key_is_missing _ _ = sorry                
\end{filecontents*}

\begin{figure*}
  \begin{minipage}{0.49\textwidth}
    \inputminted{haskell}{delete1.hs}
  \end{minipage}
  \begin{minipage}{0.49\textwidth}
    \inputminted{haskell}{delete2.hs}
  \end{minipage}
  \caption{Separation of lemmas from API functions. The functions
    \texttt{insert} and \texttt{delete} replace the more complex
    \texttt{inserting} and \texttt{deleting} from \texttt{justified-containers}.
    The library author can add any number of useful lemmas without burdening the
    user.}
\end{figure*}

\section{Case Study \#3: Encoding arbitrary properties}

\begin{figure*}[t!]
  \hspace{-2.5in}
  \scalebox{0.6}{{
  \begin{minipage}{\textwidth}
    \begin{prooftree}
      \AxiomC{}
      \RightLabel{\scriptsize (p)}\UnaryInfC{$\texttt{IsNil}(x) \wedge |x| = 0$}
      \UnaryInfC{$|x| = 0$}
      \UnaryInfC{$0 = |x|$}
      \AxiomC{}
      \RightLabel{\scriptsize (eq)}\UnaryInfC{$|x| = 1 + n$}
      \BinaryInfC{$0 = 1 + n$}
      \AxiomC{}
      \UnaryInfC{$\forall m \in \mathbb{N}.~ \neg (0 = 1 + m)$}
      \UnaryInfC{$\neg (0 = 1 + n)$}
      \BinaryInfC{$\bot$}
      \UnaryInfC{$\texttt{IsCons}(x)$}
      \RightLabel{\scriptsize (p)}\UnaryInfC{$\texttt{IsNil}(x) \wedge |x| = 0 \longrightarrow \texttt{IsCons}(x)$}
      \AxiomC{}
      \RightLabel{\scriptsize (q)}\UnaryInfC{$\texttt{IsCons}(x) \wedge |x| = 1 + |\texttt{Tail}(x)|$}
      \UnaryInfC{$\texttt{IsCons}(x)$}
      \RightLabel{\scriptsize (q)}\UnaryInfC{$\texttt{IsCons}(x) \wedge |x| = 1 + |\texttt{Tail}(x)| \longrightarrow \texttt{IsCons}(x)$}
      \AxiomC{}
      \UnaryInfC{$\forall \ell \in \texttt{List}_T.~ (\texttt{IsNil}(\ell) \wedge |\ell| = 0) \vee (\texttt{IsCons}(\ell) \wedge |\ell| = 1 + |\texttt{Tail}(\ell)|)$}
      \UnaryInfC{$(\texttt{IsNil}(x) \wedge |x| = 0) \vee (\texttt{IsCons}(x) \wedge |x| = 1 + |\texttt{Tail}(x)|)$}
      \TrinaryInfC{$\texttt{IsCons}(x)$}
      \RightLabel{\scriptsize (eq)}\UnaryInfC{$|x| = 1 + n \longrightarrow \texttt{IsCons(x)}$}
    \end{prooftree}
  \end{minipage}
    }
  }
  \caption{A proof that lists with nonzero length satisfy the \texttt{IsCons} predicate,
      in natural deduction style. Compare with the same proof using the \texttt{Proof} monad
      in listing ****; the steps after the \texttt{(|/)} operator correspond to the leftmost
      deductions in this proof tree. Note a slight difference: the listing proves
      $|x| = 1 + n \vdash \texttt{IsCons}(x)$, while the derivation in this figure
      proves $\vdash |x| = 1 + n \longrightarrow \texttt{IsCons}(x)$.}
\end{figure*}

\begin{filecontents*}{nzlic.hs}
nonzero_length_implies_cons
  :: (Length xs == Succ n) -> Proof (IsCons xs)

nonzero_length_implies_cons eq =
  do  toSpec length
   |$ or_elimR and_elimL
   |/ and_elimR
   |. symmetric
   |. transitive' eq
   |. (contradicts' $$ zero_not_succ)
   |. absurd
\end{filecontents*}

\inputminted{haskell}{nzlic.hs}

\subsection{Adding proof tactics}

For simple properties, the task of writing a proof is not too difficult. But for
more sophisticated properties, the deployment of \emph{proof tactics} becomes
critical. A proof tactic is a search strategy for proofs, usually targeted at
proving theorems of a certain shape. For example, the \texttt{Coq} tactic
\texttt{omega} is useful for proving theorems about arithmetic, while
\texttt{simpl} is useful for simplifying a complex goal.

Tactics are often designed with a specific domain in mind; to be most useful,
theory creators (and library authors) should be able to create their own tactics
when needed. For example, a library dealing extensively with fixed-width numeric types
may benefit from specific proof tactics based around the theory of bitvectors.

One approach to providing custom tactics is to leverage \texttt{GHC}'s support for
\emph{type-checker plugins}. These plugins hook into \texttt{GHC}'s $\textsf{OutsideIn}(X)$
inference algorithm, extending the algorithm's capabilities.

As a proof-of-concept, we developed a simple typechecker plugin that implements
proof by analytic tableaux. This tactic can verify the satisfiability of any
valid formula of propositional logic; the na\"ive implementation takes about
60 lines of Haskell, plus another 150 lines for the plugin that mediates between
the tableaux solver and $\textsf{OutsideIn}(X)$.

To trigger the custom tactic, we introduce an empty injective type family---hidden
from the user---and a single exported function \texttt{tableaux}.
\begin{minted}{haskell}
type family ProofByTableaux p = p' | p' -> p

tableaux :: ProofByTableaux p
tableaux = error "proof by analytic tableaux."
\end{minted}
Morally, we want to think of \texttt{ProofByTableaux p} as an alias for \texttt{p}.
By introducing it as an empty type family, we will give our type checker plugin a
********

The type-checker plugin will get a chance to intervene whenever \texttt{GHC}
attempts to solve a type equality constraint of the form \texttt{ProofByTableaux p $\sim$ p'}.
When such a constraint is met, the plugin performs the following tasks:
\begin{enumerate}
\item Convert the \emph{type} \texttt{p'} to a \emph{formula} $\Phi$ in propositional
  logic, introducing free variables for any subterms that are not built from the
  propositional logic type constructors \texttt{And}, \texttt{Or}, and so on.
\item Invoke the solver for analytic tableaux, attempting to find an assignment of truth
  values to variables such that $\neg \Phi$ is true.
\item If the solver finds such a truth assignment, report an error: the user asked us
  to apply the tactic to prove $\Phi$, but the variable assignment demonstrated that
  $\Phi$ is actually \emph{false}.
\item If the solver finds that no such truth assignment exists, then we have proven that
  $\Phi$ is valid. Tell \texttt{GHC} to discharge the constraint \texttt{ProofByTableaux p $\sim$ p'}, replacing it with \texttt{p $\sim$ p'}.
\end{enumerate}
For the user, the effect appears to be that \texttt{tableaux} can act as a value of
type \texttt{p} whenever \texttt{p} is a valid formula in propositional logic.

\begin{filecontents*}{tableaux.hs}
proof1, proof2 :: Proof (p {$\wedge$} q --> p {$\vee$} q)
  
proof1 =  and_elimL
       |. or_introL
       |\ impl_intro

proof2 = tableaux
\end{filecontents*}

\begin{figure}
  \inputminted{haskell}{tableaux.hs}
  \caption{Custom proof tactics can be implemented as type-checker plugins and
    included with libraries. Here, a proof requirement is discharged in two ways:
    once by hand, and then again by appeal to the \texttt{tableaux} plugin.
    \label{tableaux-example}}
\end{figure}

\subsection{Refinement types via phantom predicates}

(cite the \texttt{refined} library here) \cite{refined}

\bibliographystyle{abbrvnat}

\bibliography{gdp.bib}
%% \begin{thebibliography}{10}
%%   \softraggedright
  
%% \bibitem[Berkeley (1734) Berkeley]{analyst}
%%   G. Berkeley. \newblock The Analyst, a Discourse ADdressed to an Infidel Mathematician.
%%   \newblock 1734.
%% \end{thebibliography}


\end{document}
